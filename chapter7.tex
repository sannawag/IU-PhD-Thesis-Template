\chapter{Conclusion}
\label{chap:conclusion}

In this thesis, I introduce a novel data-driven algorithm for estimating and applying pitch corrections in a monophonic vocal track, while using the backing track (also called accompaniment) as a reference. The deep neural network used to predict pitch corrections is exposed to both incorrect intonation, for which it learns a correction, and intentional pitch variation, which it learns to preserve. It represents pitch as a continuous value rather than a discrete set of notes. It does not rely on a musical score, thus allowing for improvisation and harmonization in the singing performance. Results on a convolutional neural network with a gated recurrent unit layer indicate that spectral information in the backing and vocal tracks is useful for determining the amount of pitch correction required at the note level. 

The fact that musical pitch is not represented as a discrete set of notes also makes the algorithm applicable to musical traditions that differ from Western pop music with respect to the scales and pitch variation patterns used. The network in this thesis was trained on Western popular music, but could also be trained on music from other genres and cultures.

The amateur ``Intonation'' dataset used as ground truth in this thesis has a very different pitch distribution from that of a dataset built from professional performances. The results described in this thesis are thus prototypical in nature. A challenge for future work is to obtain professional-level data to permit more accurate prediction. 

The current model is built on some strong assumptions. First, the backing track is assumed to have clearly identifiable pitches---a chord progression---that serve as a reference for the vocals. Second, a note's pitch is assumed to be correctable by shifting the full note by a constant, which minimizes changes to the original performance. The modifications preserve pitch nuances and timbre, ensuring a natural sounding result that preserves the singer's style. As these assumptions are relaxed in future work, the performance of the model should improve in the current context, and the contexts to which the model can apply will expand. The model can also be developed to address other aspects of the performance, such as rhythm. 

The algorithm now first predicts the amount by which singing should be shifted in pitch, then applies the shift in post processing. An objective for future work can be to extend the model so that it directly predicts the pitch-shifted signal in an end-to-end model. 

Future work will benefit from collaboration with human-computer interaction designers, music theorists, and musicologists. A machine-learning-based algorithm can always make mistakes, and these mistakes can be addressed over time from the feedback that these collaborations will provide.

%\section{Broader impacts}
More generally, the work presented here contributes to the recent field of music information retrieval, which lies in the intersection of music and technology. The automatic pitch correction algorithm introduced here illustrates how recent technological advances can be used in the service of music. It also exemplifies the use of music technology to incorporate millenia of music theory into artistic expression and development.

Digital apps represent a primary way to interact actively with music, and they are often a first step for people getting started with making music. An app experience that is positive and is perceived as leading to musical growth may increase the probability that the user evolves to become a musician.
