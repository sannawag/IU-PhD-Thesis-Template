\chapter{Conclusion}
\label{chap:conclusion}
\section{Conclusion}
This experiment is the first iteration of a deep learning model that estimates pitch correction for a monophonic vocal track using the instrumental accompaniment track as reference. Our results on a CNN with a GRU layer indicate that spectral information in the accompaniment and vocal tracks is useful for determining the amount of pitch correction required at a note level. In chapter \ref{sec:thesis-timeline}, I describe the next steps on this project.

% . Our analysis also shows the need for developing more ways of generating natural-sounding out-of-tune singing, and moving beyond the strong assumptions the current model is based on. While the current model outputs the amount by which singing should be shifted in pitch, the model can be extended to predicted the pitch-shifted signal directly. The proposed model improves musical intonation in some scenarios, but requires more robustness to provide an improvement on average over the original or baseline systems. The model can also be trained on different musical genres than Western popular music, especially genres with more fluidly varying pitch, when data is available. 