\chapter{Musical intonation: What we learn from Auto-Tune and millenia of Western music history}

\section{Adjusting musical intonation}
This chapter provides an overview of the concept of musical intonation. It start with a loose definition, then describes two main approaches to conceptualizing intonation---ratio based and empirically derived---and how these have been debated for millenia. It then introduces Antares Auto-Tune and the underlying assumptions about musical intonation that informed its design. It shows that Auto-Tune falls strictly into the ratio-based side of the debate. This raises the question of how an autotuner could be designed using an empirical approach, and what advantages such a design might bring. Finally, it explores how Auto-Tune has been used in professional and amateur music since it became widely available in 1997. It describes positive, negative, and surprising outcomes. Chapter \ref{chap:ibr} takes this further by placing design of music technology into the framework of intervention-based design, an approach to design that develops by confronting theory with reality when implementing new technologies.

\subsection{What is musical intonation?}
Cambridge Dictionaries online (6/12/2020) defines musical intonation as: the degree to which the notes of a piece of music are played or sung exactly in  tune,  e.g.,  ``The  violinist  had  good  intonation,  and a wonderful pure tone.''. It defines \textit{in tune} as: singing or playing notes that are at the right pitch (= level) or that agree with others being sung or played. 

TODO: Also define pitch. ``Pitch versus frequency. In general, frequency is not the same as pitch. We use the term ‘‘pitch’’ in the psycho- acoustic sense of the experience of how high or low    a tone sounds. It is a purely subjective parameter—an experience of the listener that can depend on several different physical parameters.'' \cite{parncutt2018psychocultural}

While the definition in Cambridge Dictionaries focuses on the listener's perspective, Parncutt \textit{et al.} define intonation as musicians' actions: the real-time adjustment of (fundamental) frequencies in music performance.'' They elaborate this definition by describing limits of auditory perception, inharmonicity of musical tones, pitch as a subjective value versus frequency as an objective metric, and complexity and subjectivity in music \cite{parncutt2018psychocultural}.

From these definitions, we can see that precisely and comprehensively defining the concept of musical intonation is challenging. First, the subjective component makes it difficult to directly measure intonation without feedback from listeners. Second, a performer dynamically adjusts intonation over time. In some musical contexts such as jazz improvisation, a musician can transform locally bad intonation into globally good intonation, as famously expressed by bassist Victor Wooten: ``You are never more than a half-step away from a right note.''

Both definitions of intonation apply to our autotuning goal. We wish to adjust the fundamental frequency of the singing voice recording so that, in its temporal context, it agrees with the audio content in the backing track and its pitches sound correct to the listener. The practical implementation of this type of adjustment requires many music-related decisions, each of which will have an impact on how the program behaves. Decisions include determining the amount of context to use to determine a proper adjustment, choosing which audio features to use to predict corrections, and whether to apply corrections continuously, i.e., frame by frame, or constantly to a unit such as a note. This thesis describes one set of decisions, and the results it produced, but by no means provides the only way to approach the problem.

\subsection{Studies on musical intonation}
Musical intonation has the subject of research and debate throughout history. This section focuses on models in Western music as these are most directly tied to the way Auto-Tune is designed. Later sections, though, argue that the proposed program can work both in Western and non-Western musical contexts. 

Musical intonation is relevant, by definition, when two or more pitches are played together, either simultaneously or in succession. A key to studying intonation is to develop a way of measuring the interval, i.e. the relationship between the pitches. 

\subsubsection{Ratio-based measures of intonation}
\label{sec:ratio}
One natural approach to measuring an interval is to calculate the ratio between their fundamental frequencies. Pythagorean and just intonation are two ratio-based systems that define intervals as in tune, or \textit{pure}, when they minimize the length of the shared period of two sine tones at the given frequencies. Small-integer ratios minimize \textit{roughness} and \textit{beats}: periodic oscillations in amplitude caused by constructive and destructive interference of the signals, considered undesirable. An octave has a ratio of 2:1, and a fifth a ratio of 3:2, making these two intervals the most pure after the unison. This powerful concept formed the basis of Western tonality. As music became more complex, keeping all co-occuring intervals pure became mathematically impossible. Various compromises were invented. The equal-tempered scale is one such compromise, invented in the late 18th century \cite{equaltemperament}. Designed for fixed-pitch instruments, it sets the same ratio between all twelve semitones. The ratios are irrational, $2^{1/12}$, so none are pure, but all are considered close enough to sound in tune for most purposes. 

\subsubsection{Empirically derived measures of intonation}
\label{sec:empirical}
An alternative to the ratio-based conceptualization of musical intonation, as old as its counterpart, is the empirical approach. Aristoxenus wrote three books entitled ``Elements of Harmony'', where he ``argued on the basis of musical experience and intuition that the basic elements of musical structure---intervals, scales, tuning, melody---do not depend on arithmetic  proportions, as the Pythagoreans claimed, but on what we today would call auditory psychology: processes of auditory perception, cognition, memory, and recall. To understand music, we have to perceive it. To understand the musical effect or function of an interval, we have to listen to it, not make abstract calculations. To understand how melodies work, we have to perceive, remember, and reproduce them. Musicians are not aware of ratios as they perform melodies. Interval sizes vary on a continuous scale and do not generally correspond to mathematically idealized ratios'' \cite{parncutt2018psychocultural}. 

Parncutt \textit{et al.} argue in favor of the empirical approach. This section lists some of the arguments, but the reader is encouraged to refer to the article for a comprehensive list \cite{parncutt2018psychocultural}. 

First, studies measuring interval sizes in Western tonal musical performances show normal, unimodal distributions around the twelve equal divisions of the octave. The theoretical Just and Pythagorean variants are found to lie well within the distributions. Furthermore, the octave that is divided into twelve is slightly larger than 2:1, as is found in piano tuning. The studies have also show that performers stretch larger intervals, compress smaller intervals, and play sharper if they are soloists. This indicates that performers might exaggerate intonation patters for stylistic purposes. 

Second, physical, fundamental frequency and perceived pitch differ most of the time. One reason for this is nonlinearity in the cochlea’s spectrum analysis. However, perceived pitch also changes based on intensity, register, timbre, and masking effects when multiple sounds are played simultaneously. Perceived pitch can differ from frequency by up to two semitones. 

Third, rich timbres, inharmonicity (the fact that the overtone frequencies are often not exact integer ratios of the fundamental frequency), and randomization of phase via overlapping of the direct sound and its reflections make most of the beats and roughness inaudible in practice.

Fourth, there are physical limits in how precisely the human auditory system can detect pitch, for example, if a note is short. Physical limits also apply to how precise a performer can be.

Fifth, a performer's pitch can drift over time, either on purpose or through random variation. This means that the ratio between frequencies is changing over time, not locked into a specific value.

Parncutt \textit{et al.} conclude that ``[m]usical intervals are not ratios, nor are they magical mathematical entities. They are learned, approximate, perceptual distances. They emerge from a multi-generational perceptual-historical process, mediated by the physical properties of musical tones and the physiological and psychological properties and limitations of the human auditory system.''

\subsubsection{How does Auto-Tune work?}
We next summarize the functionality of Auto-Tune so that we can understand how it models musical intonation. The Auto-Tune Pro Manual \cite{antares:2018} describes this in detail. We focus the features that are relevant to this thesis. Though Auto-Tune features two modes of operation---Auto Mode, which is optimized for real-time pitch correction and effects, or for automatic adjustments, and Graph Mode, which provides a user interface for precise, manual editing of the pitch and timing---we focus on the Auto Mode. Whereas the Graph Mode enables the user to be as musically refined and nuanced as he or she wishes to be, Auto Mode is designed to be used in a similar context to the proposed program.   

Auto-Tune in Auto Mode takes as input a well-isolated, monophonic sound source. It continuously adjusts the input pitch towards a target pitch. The target pitch is the closest scale tone as determined by the current scale settings. The default scale is the chromatic, equal-tempered scale, but the user can customize the set of notes that is used by specifying the key and the scale. These can also be automatically detected using MIDI. Furthermore, the user can customize the (fixed) frequency of every note.

One of the most important parameters in Auto-Tune is the Retune Speed, which controls how rapidly the pitch correction is applied to the incoming audio. The units are milliseconds. If set to zero, the pitch is immediately moved to the target pitch, completely suppressing any vibrato or deviations in pitch. A setting between 10 and 50 milliseconds is commonly used for producing a more natural sounding effect. There is always a tradeoff between remaining close to the scale and preserving pitch variation. Some additional functionalities help reduce unwanted artifacts. One is the Humanize function, which adjust Retune Speed based on the length of the note. The Retune Speed is reduced on longer notes to prevent a static pitch, but kept fast for the short notes so that the melodic contour is accurate. Another is Flex-Tune. This control helps note transitions be less abrupt by only applying pitch correction when the performer approaches the target note. Controls also exist to amplify existing vibrato or to add a synthesized one. Finally, controls exist to preserve the singer's formant or even change it to sound like they have a longer or shorter throat. Voices are put into five categories: Soprano, Alto/Tenor, Bass, Instrument, Bass Instrument. This categorization also helps preserve a natural formant. 

\subsubsection{How conceptualization of musical interval affects the design of an autotuner}
Auto-Tune's model of pitch shows that it is designed based on the ratio conceptualization of intervals. From sections \ref{sec:ratio} and \ref{sec:empirical}, we can deduce a set of assumptions that underlie the way the program applies corrections. First, perceived pitch and fundamental frequency can be treated as equivalent. Second, proximity to a small set of frequencies---by default, the twelve notes in the equal-tempered scale---can be considered accurate or, by extension, decent intonation. Third, masking and interference from the backing track does not provide essential information for the pitch corrections. Fourth, the center pitch in every note remains constant throughout, except during note transitions at the beginning and end. 

While the simple model behind Auto-Tune makes it possible to design a program that consistently produces reliable results, it is worth pondering what nuances are lost in the process.\footnote{Parncutt \textit{et al.} recommended that ``Computer scientists [...] resist the temptation to develop and implement models of musical structure based on frequency ratios.'' I personally spent much of my early PhD thinking about how such a model could be developed, but found the task difficult. I synthesized four-part harmony with intervals based on just or Pythagorean intonation and only produced dissonant results.}. First, while the concept of intervals as ratios is useful, shifting frequencies so that the ratios of their fundamental frequencies exactly correspond to the small number of acceptable values removes the pitch variations that deviate from these values. One can argue that, in the process, part of the social phenomenon that is music is lost: the part of music that consists of a shared auditory culture, where artists and listeners learn to appreciate specific pitch patterns in specific concepts, and become part of a musical community. Second, results of psychoacoustics are ignored in favor of theoretical models of musical intonation that do not correspond to what proficient musicians do in practice. Third, the richness of vocal timbre and of interaction between the vocals and backing track are ignored. 

TODO: Blues considered out of tune (britannica).
 
While there is ample reason to consider an empirical approach to automatic pitch correction, or to develop a more complex model, one question occurs. Does moving towards an empirical representation of musical intonation force us to discard an elegant mathematical and physical theory? Parncutt \textit{et al.} argue that this is not the case. ``Physics is often thought of as an 'exact science' because it is dominated by mathematical theory. But mathematics is also an excellent tool for dealing with inexactness. Music theory is often considered mathematical and therefore exact. In fact, the quantities considered in applied mathematics vary along a spectrum from very exact to very approximate. The number ratios that correspond to musical intervals also lie somewhere along that spectrum.''

\subsection{misc}

crude comparison: make all people have the same height. Uncanny. All would have reasonable height, but put together, something is wrong. Music shows a distribution but the individual choices are complex. Pasta cooking. Miss the crunchy results and soggy ones, but also the al dente vs softer, depending on sauce. Digestible but not pleasing. The raw material: rice, water, cooking utensils, are all different. Personal individual preferences. Cooking skills. Simple model for when rice is cooked. No failed rice, but not satisfying.

\subsection{Story: what we learned from Antares}

For two decades, Antares Auto-Tune has been the world standard for professional pitch correction. We note that other tools exist, such as Melodyne. However, the way that these tools model pitch is not significantly different from how it is modeled in Auto-Tune. \cite{eckard2016}

Andy Hildebrand founded Jupiter Systems, which later became Antares Audio Technology, in 1997. He got his PhD in electrical engineering at the University of Illinois, where he got a PhD in signal processing. His full-time job involved signal processing on seismic data for oil exploration. He wrote: ``Around 1995 I was at a trade show, it was me and a couple partners, and we were with a person who was distributing our products. His wife was there, and we were talking about what products would be interesting to do next. His wife said, ``Well, Andy, why don't you make me a box that would have me sing in tune?'' I looked around at the table, and everyone just stared at their lunch plates, they didn't say a word.

So I thought, ``boy, that's a lousy idea.'' About eight or nine months into the year, I'd gone to work for a different project, and I came back to that idea, I said, ``you know, that's pretty straightforward to do, I'll do that.'' At the same trade show a year later I had producers ripping it out of my hands.'' In the interview, Hildebrand expressed surprise at the fact that artists did not simply use the Auto-Tune software as intended, to discretely fix a singer's pitch, but instead used extreme settings that produce a robotic effect. He described Western music as having a long history of innovations, and placed Auto-tuning into that continuum. 

\subsubsection{Used by professional artists}
\textit{Sunday Morning} Maroon 5 or \textit{Toxic} by Britney Spears both used Auto-tune in the expected manner. Easy to not notice unless one puts some thought into it. 

Initial goal: not everyone can sing in tune. How about if we automatically fix it? simple, not always satisfying, led to new musical style. \textit{Buy U a Drank (Shawty Snappin')} by T-Pain (feat. Yung Joc) starting at 0:02. \textit{Die For You} by The Weeknd, i.e., at 1:24 (rich voice at 0:28), or \textit{What The Price} by Migos, i.e., at 0:17 or especially 0:26, 0:44. Electropop. \textit{Anything could happen} by Ellie Goulding compare 0:00 to 0:08 to 2:28 Ke\$ha \textit{Die Young} with auto-tuning versus reconstructed. Miley Cyrus \textit{Party in the USA} 0:09 subtle versus 0:43 effect electropop versus her natural voice \textit{The Backyard Sessions - ``Jolene''} \url{https://youtu.be/wOwblaKmyVw}. Criticism, e.g., \url{https://theblackandwhite.net/36566/opinion/blogs/artists-should-stay-acoustic-auto-tune-too-often-artificial-and-overused/}. Daft Punk \textit{Harder, better, faster, stronger} 1:37 Dance/Electronic. \textit{Work} by Rihanna, Drake, 0:09 discrete, 1:00 extreme, sounds like a theremin. R\&B. 

\subsection{What do we want? My research question} A program that automatically adjusts pitch of singing voice given a fixed backing track. It should sound more in tune after the adjustment without sacrificing the overall quality of the sound. This leaves many open questions. What is in tune? What aspects of overall quality do we wish to preserve? What is automatic?

Use patterns from performances. What is the best way for the program to access audio features and context to make good predictions? How do we evaluate? How should we represent pitch: notes, frames? How do we apply the shifts? How do we preserve natural sound? What is our scope? Hobby karaoke, post-processing.

% This is a figure in landscape orientation
%\begin{sidewaysfigure}
%\includegraphics[width=\textwidth]{figures/exampleFigure.png}
%\caption{This is another example Figure, rotated to landscape orientation.}
%\label{LandscapeFigure}
%\end{sidewaysfigure}
