\chapter{Introduction}
\label{chap:thesis-intro}
%\section{Post-processing of user-generated audio: An overview}
%\label{sec:challenges-intro}
%1. Introduction to the introduction. 
%    1. Deep autotuner
%        1. Automatic pitch correction system (define)
%        2. DNN
%        3. data-driven (define)
%        4. relationship between spectrograms/time-frequency transformations (define)
%        5. trained on real-world singing
%        6. can be adapted to musical genres w/o equal-tempered
%        7. no musical score: harmonize improvise
%        8. respect nuanced variations of sung pitch 
%        9. estimates amount of unintended pitch shift
Digital music builds on a rich music tradition in the acoustic realm, but also differs from it by nature. Before digital music can reach our ears, it needs to be represented as data that a computer can process. Design and engineering decisions lie behind this representation, from the sound wave itself---stored as a sequence of numbers---to musical structure, including melody, harmony, and rhythm. This thesis focuses on the question of representation of musical pitch in the digital realm, in the context of a pitch correction algorithm for singing voice. The way musical pitch is represented will affect how the notes are adjusted, and by extension the listener's musical experience. This thesis covers studies of how physical measures of pitch, such as frequency and timbre, map to what we hear through a complex psychoacoustic process influenced by our musical upbringing, and determine whether we consider a note to be ``in tune'' or not. It introduces a pitch correction algorithm design that strives to relate digital representation to the complex and rich way we experience pitch.

Music making with family, friends, and the wider community is one of the universally enjoyed activities across the world. In recent years, digital options have emerged in applications such as Smule, Spotify, Cadenza, YouTube, and TikTok. These enable people to share their recordings with their peers in other locations, and provide tools for collaboration and audio processing that are only possible in the digital realm. One category of tools is post-processing, which involves editing the track after it has been recorded to make it the best possible quality. Automatic pitch correction to make a performance sound in tune falls into this category. 

Why not just leave the recording unaltered? As anyone who has tried to photograph a beautiful landscape might relate to, capturing the natural colors, beauty, and atmosphere of the scene is very challenging. Image post-processing might actually make the outcome more realistic or, alternatively, focus the viewer on aspects of the landscape that would not have stood out when present in person. In the same way, a performance heard live versus recorded can be a substantially different artistic experience, where the listener is hearing the performance through the recording and playback pipeline, outside the original acoustic setting. Post-processing of audio can enhance the listening experience. 

The process of producing a digital recording can range from professional to recreational. The professional kind involves use of professional audio-editing software, high-end microphones, and recording spaces with good acoustics, all of which require considerable time and resources. It results in a high-quality, polished result. The recreational kind often involves multipurpose recording devices such as smartphones, and typically involves less time and resources. Music apps can serve as a platform for recreational music making. Apps can provide a meaningful musical opportunity. During my internship with Smule, Inc, a singing app, I heard about users who would take a ten-minute break in their workday to sing, then would write to the company sharing how that short singing break brought them joy and reduced their stress. Recreational musicians may not wish to spend much time editing their recording, or have the resources or training to do so, but still wish use post-processing tools built into the app that apply automatic pitch correction or other effects such as reverb. These post-processing tools do not replace professional audio editing, but are recognized as improving the quality of the recording with remarkably little effort or cost. Although post-processing tools fall short of bring a recording up to a professional level, they may well make it more pleasing to a listener. A parallel can be seen when a person uses a spell-checker to improve the quality of their writing, even when writing simple text such as an email. The ability of the spell-checker to remove minor errors produces a more polished result, which can make a big difference, especially given the high stakes of sharing content in a recorded format.

Digital apps may be the primary way that many people interact actively with music, or the first approach people try when getting started with music. The quality of the experience and its potential to lead to musical growth may determine whether a user keeps making music or gives it up.

\section{Overview}
This thesis addresses the task of developing a data-driven algorithm for automatic pitch correction. Existing commercial systems usually discretize the pitch to a small number of values \cite{antares:2016}. Vocal track notes are usually shifted to be centered around pitches in a user-defined score, or mapped to the closest pitch among the twelve equal-tempered scale degrees. The resulting model of pitch does not reflect the smooth variation of pitch in continuously controlled instruments such as voice or violin, and can produce a robotic-sounding result. The proposed pitch correction system uses a deep neural network trained to predict pitch shifts based on audio patterns in real-world singing examples. Through these examples, the system is exposed to both incorrect intonation, for which it learns a correction, and intentional pitch variation, which it learns to preserve. It treats pitch as a continuous value rather than a discrete set of notes and does not rely on a musical score, thus allowing for improvisation and harmonization in the singing performance. The fact that it is not bound to a discrete set of notes also means that it can be adapted to many different musical cultures, regardless of the scales used in these cultures. 

%\section{Background}
%2. Personal background: overarching topic
%    1. Technology and music have traditionally built on each other. 
%    - Undergraduate acoustic intrument, rich sounds, 
%    - Inspired by renaissance choir music
%    - Pythagoras, ratio theory, harmony of the spheres inspired me in intonation endeavors, 
%    - Stories of choirs shifting global pitch down over time to sound in tune
%    - Magic of a violin solo in Thais Massenet that hit just the right pitches
%    - jazz, always one note off. Classical music: anxious of making a mistake that would ruin the magic. Brick in a giant building of sound, didn’t want to be the one that made it tumble over
%    - Soundgarden and imperfection
%    - Magic of pitch bending in bollywood music
%    - I also found intonation very difficult: my bassoon professor McLean described how a bad timbre can make a note sound out of tune even though the tuner measures the correct frequency
%    - Bassoonist Diego Chenna had a story of a wind player who was out of tune with the rest of the orchestra, but pointed at his tuner and said he was right because the light was green
%    - Personally struggled with intonation, ear infection that shifted my perfect pitch, still confused sometimes.
%    - No easy way of reconciling all these ideas, but they all brought richness
%    - Got into music informatics, a few years later this is the overarching theme of the thesis
%    - Also enjoyed pop music, digital effects, fascinating timbres
%    - love-hate relationship with auto-tune, sometimes wonderful, sometimes left me feeling empty
%    - Not many other systems
%    - Would not have expected that auto-tuning would end up being my thesis topic

\section{Contribution}
%Deep autotuner is 
%    1. Auto-Tune vs autotune
%    6. Tools for amateur musicians to develop their singing within a musical culture, refine ear
%    7. 
%    8. Can a DNN learn intonation patterns from a time-frequency transformation and use those to predict %pitch corrections
%    9. Can the DNN preserve intended pitch variation while detecting unwanted?
%    10. Can the DNN make predictions without a musical score?
%    11. Automatic pitch correction system 
%    12. DNN
%    13. data-driven
%    14. relationship between spectrograms
%    15. trained on real-world singing
%    16. can be adapted to musical genres w/o equal-tempered
%    17. no musical score: harmonize improvise
%    18. respect nuanced variations of sung pitch 
%    19. estimates amount of unintended pitch shift
%    20. post-processing
%    21. Contribution
%        1. prototype model for the task
%        2. Spectrogram-based sequential pitch correction predictions
%        3. DNN model
%        4. Present a data collection technique for subjective task
%            1. Can be used for other collection
%        5. Explore how this system could be turned into a usable system in practical situations

The work in this thesis contributes to the recent field of music information retrieval, which lies in the intersection of music and technology. The automatic pitch correction system proposed in this thesis is developed in the context of the following questions: How can recent technological advances be used in the service of music and art in general? How does this system fit into the context of millenia of music theory? How can we incorporate music theory into music technology, and how can technology provide new means for artistic expression and development? How does a data-driven approach relate to existing systems such as Antares Auto-Tune? 

As far as I know, the automatic pitch correction system proposed in this thesis is the first one that incorporates concepts from psychoacoustics, physics of sound, and cultural practices regarding musical intonation into its design. Its contributions include:
\begin{itemize}
    \item Predictions of pitch corrections based on the time-frequency content of the vocals and backing tracks i.e., the alignment of the harmonics
    \item Use of the backing track chord progression to predict pitch shifts that make the vocals sound in tune
    \item A data-driven approach that is designed to preserve intended pitch variation while detecting unwanted deviations
    \item An adaptation of the deep neural network architecture including convolutional layers for feature extraction and recurrent layers for sequential processing to the task of automatic pitch correction
    \item Adaptability to any musical culture, as long as training data is available
    \item No need for a musical score
    \item An note boundary detection system
    \item A first step towards a data-driven approach to automatic pitch corection. Existing approaches tend to be model-driven.
    \item The ``Intonation'' dataset of in-tune singing performances, including the time-frequency magnitude transformation of the backing tracks and other metadata
    \item A commentary on how this system could be turned into a usable system in practical situations, despite the fact that it will make mistakes
\end{itemize}

\section{Challenges in generating a natural sounding result}

Automatic singing pitch correction is a commonly desired application for digital recordings of singing. However, making a singer's pitch track sound more in tune is not always straightforward. A human listener with a moderate level of musical understanding can often detect the out-of-tune notes and predict the amount and direction of the pitch shift required to bring the note back in tune, all without requiring access to the musical score. However, commercially available pitch correction software depends on a synchronized score for the target pitch \cite{antares:2016}. The lack of knowledge about the target pitch of the sung melody can make a potential automated system suffer in the pitch correction task.

The priority with both is to output a result that sounds natural and aesthetically pleasing. If this is not the case, the user will prefer the unprocessed recording. 

Realistic data is hard to generate. The first challenge is collecting examples of in-tune singing: Publicly available datasets of singing performances typically mix performances of all levels of singing. The second challenge---if using supervised training---is to design data pairs where, for example, each pair is identical except for the vocals pitch. Such pairs are difficult to come across naturally, making realistic data synthesis a viable approach.

\section{Scope}
%4. Scope of the topic
%    1. Post-procesing
%    2. amateur singing
%    3. smartphone app
The proposed system is designed for amateur singing and focuses on situations where a singer wishes to apply simple post-processing---for example, on their smartphone---without using professional audio editing software. It requires for the vocals and backing track to be separate, and for the vocals to be monophonic and free of noise. The system is designed to be used as a post-processing tool. It may be adapted for real-time processing, but the task is out of the scope of this thesis.

The system is built on some strong assumptions, which might not be accurate. First, that the backing track has clearly identifiable pitches---a chord progression---which serves as a reference for the vocals. Second, that a singer targets a specific frequency per note, around which all pitch variations are centered. Third, that the dataset used to train it is in-tune enough for this prototype, despite consisting of amateur singing. %tune
%5. Outline your epistemological and ontological position
%    1. In this thesis, compare a model-driven approach to the selected data-driven approach, describe how %each contributes to increased knowledge, and why I chose a data-driven approach
%    2. Address issues that can come up when a data-driven approach outputs an error
%6. State the hypotheses (if you are using any)
%    1. backing track has clearly identifiable pitches---a chord progression---which serves as a reference %for the vocals
%    2. a singer targets a specific frequency per note, around which all pitch variations are centered: can %shift frequency by note
%    3. Assumption that the dataset we collect is in-tune enough for this prototype, despite not being in %tune
%    4. Built within context of mostly Western music, but show that it can be customized to many musical cultures
\section{Main findings}
The proposed deep neural network is trained in a supervised manner on pairs on in-tune versus out-of-tune performances. Generating these pairs required de-tuning the in-tune performances to synthesize out-of-tune singing. In this thesis, I train multiple model configurations on the task of correcting the synthetically de-tuned singing. I compare different approaches to splitting a pitch track into notes, different random distributions for de-tuning the notes, and different architectures. I find that the configuration that produces the most accurate results splits notes based on where there is silence, uses a Hidden Markov Model \cite{rabiner1989tutorial} to generate pitch deviations, and is limited to a single Gated Recurrent Unit \cite{chung2014empirical} layer per note instead of adding an additional layer that would provide more temporal context. I compare results by plotting histograms of pitch deviations both on synthetically de-tuned data and on real-world performances by amateur singers from the MIR-1K dataset \cite{hsu2009improvement}. The histogram based on the selected model's outputs most resembles the ground-truth training data. A qualitative subjective listening test finds that the proposed approach surpasses the performance of a baseline, which shifts the median of each note to the nearest equal-tempered scale degree. Comparing the proposed approach with the original test performances, the proposed corrections lead listeners to confidently prefer the edited version in approximately half of ten samples, and to ambiguity in many of the remaining samples.

%    2. Subjective test finds that …  
%7. Briefly describe your methodology
%    1. The proposed deep neural network consists of convolutional layers for feature extraction followed by %gated recurrent units for sequential processing.
%    2. Supervised training: synthesize de-tuned
%8. Discuss the main findings
%    1. Find that DNN reduces average prediction loss to … cents on synthesized out-of-tune singing
%    2. Subjective test finds that … 

\section{Outline}
The layout of the thesis is as follows.
%9. Discuss the layout of the thesis
%    1. 2: musical intonaton: ratio-based, empirically derived, auto-tune, conceptualization in this thesis
%    2. 3: model free: music representation in software, model-driven vs model-free approaches, concepts of %control, interpretability, and expressivity, reason behind DNN
%    3. 4: technical presentation: related work in MIR, DL, ASP, proposed system, and experimental %configuration
%    4. 5: dataset generation, Smule 
%    5. 6: results
%    6. 7: conclusion and future work

\subsection{Chapter \ref{chap:intonation}}
Chapter \ref{chap:intonation} provides a musical background for the design of the proposed system. It places it in the discussion on musical intonation over millenia. It then introduces two standard conceptualizations of musical intonation, relevant definitions, and musical cultures that use intonation in different ways. This chapter also introduces Antares Auto-Tune, one of the music industry standards for pitch correction, discussing its advantages and disadvantages, and what can be learned from it when developing the proposed system.

\subsection{Chapter \ref{chap:tech-background}}
%    2. 3: model free: music representation in software, model-driven vs model-free approaches, concepts of %control, interpretability, and expressivity, reason behind DNN
Chapter \ref{chap:tech-background} discusses the technical background. It provides an overview of music representation in software and compares model-driven approaches to music technology data-driven approaches, including how they affect control, interpretability, and expressivity of the programs. It concludes with reasons behind the choice of a deep neural network for the task of automatic pitch correction.

\subsection{Chapter \ref{chap:thesis-autotuner}}
Chapter \ref{chap:thesis-autotuner} provides a technical presentation of the proposed system. It starts with an overview of related work in music information retrieval, deep learning, and audio signal processing. It then describes in detail the proposed system. This includes note boundary detection techniques, pitch de-tuning techniques, model architecture choices, and the experimental configuration.
%    3. 4: technical presentation: related work in MIR, DL, ASP, proposed system, and experimental %configuration

\subsection{Chapter \ref{chap:thesis-damp}}
Chapter \ref{chap:thesis-damp} describes how the ``Intonation'' dataset was collected, details about the dataset, and how the collection technique can be used to generate datasets for other tasks where the target is subjective---as it is in the case of musical intonation. It also describes shortcomings related to genre bias in the current dataset, and how this issue can be fixed in future work.

\subsection{Chapter \ref{chap:results}}
Chapter \ref{chap:results} describes results both on the synthesized test set and the real-world dataset. It includes a comparison of the results using pitch deviation histograms. It also includes a comparison of the pitch deviation histograms of the selected model with the ground truth ``Intonation'' dataset, a professional dataset, the real-world test dataset before corrections, and the synthetically de-tuned data. This analysis is followed by a qualitative listening test that provides insights into the way the model works. The analysis indicates that the proposed approach is more reliable than a conceptually and computationally simple baseline. It also indicates that the proposed approach effectively utilizes pitch content from the backing track when this is close to the melody.

\subsection{Chapter \ref{chap:conclusion}}
Chapter \ref{chap:conclusion} concludes the thesis, providing a summary of the takeaways from this thesis. It presents the proposed automatic pitch correction as a prototype, describes its current limitations, and how these might be addressed in future work.


%    4. 5: dataset generation, Smule 
%    5. 6: results
%    6. 7: conclusion and future work


