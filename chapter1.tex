\chapter{Introduction}
\label{chap:thesis-intro}
%\section{Post-processing of user-generated audio: An overview}
%\label{sec:challenges-intro}
%1. Introduction to the introduction. 
%    1. Deep autotuner
%        1. Automatic pitch correction system (define)
%        2. DNN
%        3. data-driven (define)
%        4. relationship between spectrograms/time-frequency transformations (define)
%        5. trained on real-world singing
%        6. can be adapted to musical genres w/o equal-tempered
%        7. no musical score: harmonize improvise
%        8. respect nuanced variations of sung pitch 
%        9. estimates amount of unintended pitch shift
Through college, my music making was first and foremost in the acoustic realm. I was trained in the Western Classical tradition, first on piano, then on bassoon. Even then, I interacted with digital music on a daily basis, through the radio, music streaming apps, electric keyboards, and tools such as microphones, tuners, and recording devices. In college, I grew curious about the representations of music as data in the digital ream. I became aware of how behind all of them were design decisions by audio and software engineers. I wished to understand how these representations could affect our experience of music, for the better, for the worse, or some of both. Conveniently, a graduate degree existed for this, named music informatics. 

Throughout my graduate studies, I have grappled with the question of music representation. Another question that has emerged is the role of music-making apps. Apps can easily come across as ``toys'', too musically limiting to enable the user's lifelong pursuit of excellence that is music learning. Attending the Audio Developer Conference in 2017\footnote{Thank you to Google and my intern host, Glenn Kasten, for funding my trip to the Audio Developer Conference.}, Julian Storer in his keynote\footnote{``Julian Storer - Keynote: Does your code actually matter? (ADC’17).'' YouTube Video, 0:00. Posted November 17, 2017. https://youtu.be/Yd0Ef6uzJb0} described how even engineers working on digital audio processing tools for professional musicians sometimes wondered whether they were building ``gadgets''. 

Since that keynote, I have come to the conclusion that apps have the potential to play a significant role in one's musical experience. During my internship with Smule, Inc.---a singing app---in 2018, I learned how some users will take a ten-minute break in their car in the middle of a workday to sing. Many have written to the company to thank it for bringing them joy and relief from stress. For some people, these ten-minute breaks are all the music that they have the time to make on a regular basis, and I found meaning in making these experiences as musically rich as possible. Having personally started singing during graduate school, I found that Smule provided a good framework for learning songs, and was inspired by the experience.

For others, an app can serve as an entryway into music. Especially in the case of people who do not grow up with much exposure to music, or do not have acoustic musical instruments easily available, digital audio and apps might be the main way to interact with music. The quality of the sound and musical richness in these apps might even influence whether a person develops a deeper interest in music making or gives it up. 

Music apps often offer the option of post-processing: editing the track after it has been recorded to make it the best possible quality. One type of editing is automatic pitch adjustment to make the performance sound in tune. This particular post-processing technique is called automatic pitch correction and is the focus of this thesis. 

Some users opt to use professional audio-editing software. Other users treat the production of audio more recreationally. Though users may not wish to spend much time editing their recording, they often still use post-processing tools built into the app that apply automatic pitch correction or other effects such as reverb. These tools do not make the recording sound professional, but can result in an outcome that the user is pleased with and is motivated to share with friends. They are also useful for users who do not have access to professional software or recording spaces, or find their usage difficult because they are not trained in audio editing. 

Why not just leave the recording unaltered? As anyone who has tried to photograph a beautiful landscape might relate to, capturing the natural colors, beauty, and atmosphere of the scene is very challenging. Applying color filters and cropping or rotating can refine the result, turning it into a better artistic experience. In the same way, a performance heard live versus recorded can be a substantially different artistic experience, where the listener is hearing the performance as it was recorded through the microphone, and without the atmosphere in the room. Post-processing of audio can help make it nicer to listen to in its digital setting. A parallel can be seen when a person uses a spell-checker to improve the quality of their writing, even when writing simple text such as an email. The ability of the spell-checker to remove minor errors produces a more polished result, which can make a big difference, especially given the high stakes of sharing content that is potentially permanent. % can provide tools that are different from live. Image of flower

\section{Overview}
This thesis addresses the task of developing a data-driven algorithm for automatic pitch correction. Existing commercial systems usually discretize the pitch to a small number of values \cite{antares:2016}. Vocal track notes are usually shifted to be centered around pitches in a user-defined score, or mapped to the closest pitch among the twelve equal-tempered scale degrees. The resulting model of pitch does not reflect the smooth variation of pitch in continuously controlled instruments such as voice or violin, and can produce a robotic sounding result. The proposed pitch correction system uses a deep neural network trained to predict pitch shifts based on audio patterns in real-world singing examples. Through these examples, the system is exposed to both incorrect intonation, for which it learns a correction, and intentional pitch variation, which it learns to preserve. It treats pitch as a continuous value rather than a discrete set of notes and does not rely on a musical score, thus allowing for improvisation and harmonization in the singing performance. The fact that it is not bound to a discrete set of notes also means that it can be adapted to many different musical cultures, regardless of the scales used in these cultures. 

%\section{Background}
%2. Personal background: overarching topic
%    1. Technology and music have traditionally built on each other. 
%    - Undergraduate acoustic intrument, rich sounds, 
%    - Inspired by renaissance choir music
%    - Pythagoras, ratio theory, harmony of the spheres inspired me in intonation endeavors, 
%    - Stories of choirs shifting global pitch down over time to sound in tune
%    - Magic of a violin solo in Thais Massenet that hit just the right pitches
%    - jazz, always one note off. Classical music: anxious of making a mistake that would ruin the magic. Brick in a giant building of sound, didn’t want to be the one that made it tumble over
%    - Soundgarden and imperfection
%    - Magic of pitch bending in bollywood music
%    - I also found intonation very difficult: my bassoon professor McLean described how a bad timbre can make a note sound out of tune even though the tuner measures the correct frequency
%    - Bassoonist Diego Chenna had a story of a wind player who was out of tune with the rest of the orchestra, but pointed at his tuner and said he was right because the light was green
%    - Personally struggled with intonation, ear infection that shifted my perfect pitch, still confused sometimes.
%    - No easy way of reconciling all these ideas, but they all brought richness
%    - Got into music informatics, a few years later this is the overarching theme of the thesis
%    - Also enjoyed pop music, digital effects, fascinating timbres
%    - love-hate relationship with auto-tune, sometimes wonderful, sometimes left me feeling empty
%    - Not many other systems
%    - Would not have expected that auto-tuning would end up being my thesis topic

\section{Contribution}
%Deep autotuner is 
%    1. Auto-Tune vs autotune
%    6. Tools for amateur musicians to develop their singing within a musical culture, refine ear
%    7. 
%    8. Can a DNN learn intonation patterns from a time-frequency transformation and use those to predict %pitch corrections
%    9. Can the DNN preserve intended pitch variation while detecting unwanted?
%    10. Can the DNN make predictions without a musical score?
%    11. Automatic pitch correction system 
%    12. DNN
%    13. data-driven
%    14. relationship between spectrograms
%    15. trained on real-world singing
%    16. can be adapted to musical genres w/o equal-tempered
%    17. no musical score: harmonize improvise
%    18. respect nuanced variations of sung pitch 
%    19. estimates amount of unintended pitch shift
%    20. post-processing
%    21. Contribution
%        1. prototype model for the task
%        2. Spectrogram-based sequential pitch correction predictions
%        3. DNN model
%        4. Present a data collection technique for subjective task
%            1. Can be used for other collection
%        5. Explore how this system could be turned into a usable system in practical situations

The work in this thesis contributes to the recent field of music information retrieval, which lies in the intersection of music and technology. The automatic pitch correction system proposed in this thesis is developed in the context of the following questions: How can recent technological advances be used in the service of music and art in general? How does this system fit into the context of millenia of music theory? How can we incorporate music theory into music technology, and how can technology provide new means for artistic expression and development? How does a data-driven approach relate to existing systems such as Antares Auto-Tune? 

As far as I know, the automatic pitch correction system proposed in this thesis is the first one that incorporates concepts from psychoacoustics, physics of sound, and cultural practices regarding musical intonation into its design. Its contributions include:
\begin{itemize}
    \item Predictions of pitch corrections based on the time-frequency content of the vocals and backing tracks i.e., the alignment of the harmonics
    \item Use of the backing track chord progression to predict pitch shifts that make the vocals sound in tune
    \item A data-driven approach that is designed to preserve intended pitch variation while detecting unwanted deviations
    \item An adaptation of the deep neural network architecture including convolutional layers for feature extraction and recurrent layers for sequential processing to the task of automatic pitch correction
    \item Adaptability to any musical culture, as long as training data is available
    \item No need for a musical score
    \item An note boundary detection system
    \item A first step towards a data-driven approach to automatic pitch corection. Existing approaches tend to be model-driven.
    \item The ``Intonation'' dataset of in-tune singing performances, including the time-frequency magnitude transformation of the backing tracks and other metadata
    \item A commentary on how this system could be turned into a usable system in practical situations, despite the fact that it will make mistakes
\end{itemize}

\section{Challenges in generating a natural sounding result}

Automatic singing pitch correction is a commonly desired application for digital recordings of singing. However, making a singer's pitch track sound more in tune is not always straightforward. A human listener with a moderate level of musical understanding can often detect the out-of-tune notes and predict the amount and direction of the pitch shift required to bring the note back in tune, all without requiring access to the musical score. However, commercially available pitch correction software depends on a synchronized score for the target pitch \cite{antares:2016}. The lack of knowledge about the target pitch of the sung melody can make a potential automated system suffer in the pitch correction task.

The priority with both is to output a result that sounds natural and aesthetically pleasing. If this is not the case, the user will prefer the unprocessed recording. 

Realistic data is hard to generate. The first challenge is collecting examples of in-tune singing: Publicly available datasets of singing performances typically mix performances of all levels of singing. The second challenge---if using supervised training---is to design data pairs where, for example, each pair is identical except for the vocals pitch. Such pairs are difficult to come across naturally, making realistic data synthesis a viable approach.

\section{Scope}
%4. Scope of the topic
%    1. Post-procesing
%    2. amateur singing
%    3. smartphone app
The proposed system is designed for amateur singing and focuses on situations where a singer wishes to apply simple post-processing---for example, on their smartphone---without using professional audio editing software. It requires for the vocals and backing track to be separate, and for the vocals to be monophonic and free of noise. The system is designed to be used as a post-processing tool. It may be adapted for real-time processing, but the task is out of the scope of this thesis.

The system is built on some strong assumptions, which might not be accurate. First, that the backing track has clearly identifiable pitches---a chord progression---which serves as a reference for the vocals. Second, that a singer targets a specific frequency per note, around which all pitch variations are centered. Third, that the dataset used to train it is in-tune enough for this prototype, despite consisting of amateur singing. %tune
%5. Outline your epistemological and ontological position
%    1. In this thesis, compare a model-driven approach to the selected data-driven approach, describe how %each contributes to increased knowledge, and why I chose a data-driven approach
%    2. Address issues that can come up when a data-driven approach outputs an error
%6. State the hypotheses (if you are using any)
%    1. backing track has clearly identifiable pitches---a chord progression---which serves as a reference %for the vocals
%    2. a singer targets a specific frequency per note, around which all pitch variations are centered: can %shift frequency by note
%    3. Assumption that the dataset we collect is in-tune enough for this prototype, despite not being in %tune
%    4. Built within context of mostly Western music, but show that it can be customized to many musical cultures
\section{Main findings}
The proposed deep neural network is trained in a supervised manner on pairs on in-tune versus out-of-tune performances. Generating these pairs required de-tuning the in-tune performances to synthesize out-of-tune singing. In this thesis, I train multiple model configurations on the task of correcting the synthetically de-tuned singing. I compare different approaches to splitting a pitch track into notes, different random distributions for de-tuning the notes, and different architectures. I find that the configuration that produces the most accurate results splits notes based on where there is silence, uses a Hidden Markov Model \cite{rabiner1989tutorial} to generate pitch deviations, and is limited to a single Gated Recurrent Unit \cite{chung2014empirical} layer per note instead of adding an additional layer that would provide more temporal context. I compare results by plotting histograms of pitch deviations both on synthetically de-tuned data and on real-world performances by amateur singers from the MIR-1K dataset \cite{hsu2009improvement}. The histogram based on the selected model's outputs most resembles the ground-truth training data. A qualitative subjective listening test finds that the proposed approach surpasses the performance of a baseline, which shifts the median of each note to the nearest equal-tempered scale degree. Comparing the proposed approach with the original test performances, the proposed corrections lead listeners to confidently prefer the edited version in approximately half of ten samples, and to ambiguity in many of the remaining samples.

%    2. Subjective test finds that …  
%7. Briefly describe your methodology
%    1. The proposed deep neural network consists of convolutional layers for feature extraction followed by %gated recurrent units for sequential processing.
%    2. Supervised training: synthesize de-tuned
%8. Discuss the main findings
%    1. Find that DNN reduces average prediction loss to … cents on synthesized out-of-tune singing
%    2. Subjective test finds that … 

\section{Outline}
The layout of the thesis is as follows:
%9. Discuss the layout of the thesis
%    1. 2: musical intonaton: ratio-based, empirically derived, auto-tune, conceptualization in this thesis
%    2. 3: model free: music representation in software, model-driven vs model-free approaches, concepts of %control, interpretability, and expressivity, reason behind DNN
%    3. 4: technical presentation: related work in MIR, DL, ASP, proposed system, and experimental %configuration
%    4. 5: dataset generation, Smule 
%    5. 6: results
%    6. 7: conclusion and future work

\subsection{Chapter \ref{chap:intonation}}
Chapter \ref{chap:intonation} provides a musical background for the design of the proposed system. It places it in the discussion on musical intonation over millenia. It then introduces two standard conceptualizations of musical intonation, relevant definitions, and musical cultures that use intonation in different ways. This chapter also introduces Antares Auto-Tune, one of the music industry standards for pitch correction, discussing its advantages and disadvantages, and what can be learned from it when developing the proposed system.

\subsection{Chapter \ref{chap:tech-background}}
%    2. 3: model free: music representation in software, model-driven vs model-free approaches, concepts of %control, interpretability, and expressivity, reason behind DNN
Chapter \ref{chap:tech-background} discusses the technical background. It provides an overview of music representation in software and compares model-driven approaches to music technology model-free approaches,  including how they affect control, interpretability, and expressivity of the programs. It concludes with reasons behind the choice of a deep neural network for the task of automatic pitch correction.

\subsection{Chapter \ref{chap:thesis-autotuner}}
Chapter \ref{chap:thesis-autotuner} provides a technical presentation of the proposed system. It starts with an overview of related work in music information retrieval, deep learning, and audio signal processing. It then describes in detail the proposed system and the experimental configuration.
%    3. 4: technical presentation: related work in MIR, DL, ASP, proposed system, and experimental %configuration

\subsection{Chapter \ref{chap:thesis-damp}}
Chapter \ref{chap:thesis-damp} describes how the ``Intonation'' dataset was collected, details about the dataset, and how the collection technique can be used to generate datasets for other tasks where the target is subjective, as it is in the case of musical intonation. It also describes shortcomings related to genre bias in the current dataset, and how this issue can be fixed in future work.

\subsection{Chapter \ref{chap:results}}
Chapter \ref{chap:results} describes results both on the synthesized test set and in the listening test. It shows that...

\subsection{Chapter \ref{chap:conclusion}}
Chapter \ref{chap:conclusion} concludes the thesis, providing a summary and exploring future work. Future work includes exploration of end-to-end systems for automatic pitch correction. 


%    4. 5: dataset generation, Smule 
%    5. 6: results
%    6. 7: conclusion and future work


